{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c947354",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time, scipy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import wasserstein_distance\n",
        "import scipy.signal\n",
        "import time\n",
        "import freeDeconvolution\n",
        "#import subordination, sampling, elkaroui\n",
        "import multiprocessing as mp\n",
        "import json\n",
        "\n",
        "T = np.arange(0,10, 0.2)\n",
        "nu = np.array( [complex(0.1*a,b) for a in range(0  , 10) for b in [0.01,0.1]] )\n",
        "\n",
        "# Returns Scenario in the form of p eigenvalues\n",
        "def gen_matrix(Scenario, p):\n",
        "        np.random.seed(seed=None)\n",
        "        if Scenario==\"Case1\":\n",
        "            population_spectrum = np.ones( p )\n",
        "\n",
        "        elif Scenario==\"Case2\" or Scenario==\"Case2.2\" or Scenario==\"Case2.3\" :\n",
        "            if Scenario==\"Case2\":\n",
        "                support = np.array( [1, 2] )\n",
        "                weights = np.array( [1, 1] )\n",
        "            elif Scenario==\"Case2.2\" :\n",
        "                weights = np.array( [1, 1] )\n",
        "                support = np.array( [1, 1.3] )\n",
        "            else :\n",
        "                weights = np.array( [1, 1,1,1,1] )\n",
        "                support = np.array( [1, 2,3,5,6] )\n",
        "            weights = weights/np.sum( weights )\n",
        " \n",
        "            population_cdf = np.cumsum( weights )\n",
        "\n",
        "            population_spectrum = np.zeros( (p,) )\n",
        "            block_begin = 0\n",
        "            for i in range( len(weights) ):\n",
        "                block_end = int( population_cdf[i]*p )\n",
        "                population_spectrum[block_begin:block_end] = support[i]\n",
        "                block_begin = block_end\n",
        "\n",
        "        elif Scenario==\"Case3\":\n",
        "            c = 1\n",
        "            indices = np.arange( 0, p, 1)\n",
        "            toeplitz_row    = 0.3**indices\n",
        "            toeplitz = scipy.linalg.toeplitz( toeplitz_row)\n",
        "            \n",
        "            population_spectrum, U = np.linalg.eig(toeplitz)\n",
        "            population_spectrum = np.sort( population_spectrum )\n",
        "        else:\n",
        "            print( \"Please specify a scenario...\" )\n",
        "            raise Error()\n",
        "        \n",
        "        return(population_spectrum)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e3754a40",
      "metadata": {},
      "source": [
        "# I. Generate experiments JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87352fd7",
      "metadata": {},
      "outputs": [],
      "source": [
        "N_range   = [ 64, 128, 192, 256, 320, 384, 448, 512]\n",
        "nb_itr    = 10\n",
        "Scenarios = [ \"Case1\", \"Case2\", \"Case2.2\", \"Case2.3\", \"Case3\"]\n",
        "\n",
        "DOEs = []\n",
        "\n",
        "# Loop over scenarios\n",
        "for Scenario in Scenarios:\n",
        "    print( f'''  |- Scenario {Scenario}''')\n",
        "    # Loop over iterations\n",
        "    for iteration in range(nb_itr):\n",
        "        # Loop over N\n",
        "        for N in N_range:\n",
        "            T = np.arange(0,10, 0.2)\n",
        "            nu = np.array( [complex(0.1*a,b) for a in range(0  , 10) for b in [0.01,0.1]] )\n",
        "            c = 1\n",
        "            p = int(c*N)\n",
        "\n",
        "            population_spectrum = gen_matrix(Scenario, p)\n",
        "            diag                = freeDeconvolution.sampling.sample_wishart( p, N, population_spectrum )\n",
        "\n",
        "            population_cdf = np.zeros_like( T )\n",
        "            for i in range( len(T) ):\n",
        "                t = T[i]\n",
        "                population_cdf[i] = np.count_nonzero( population_spectrum <= t )\n",
        "            population_cdf = population_cdf/p\n",
        "            #\n",
        "            DOEs.append( {\n",
        "                \"Scenario\": Scenario,\n",
        "                \"N\"       : N,\n",
        "                \"observed_spec\"    : list(diag),\n",
        "                \"population_spec\"  : list(population_spectrum),\n",
        "                \"population_cdf\"   : list(population_cdf),\n",
        "                \"results_by_method\": {}\n",
        "            } )\n",
        "        #\n",
        "    #\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30700c90",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs.json\", \"w\") as f:\n",
        "    json.dump( DOEs, f, indent=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8d2a5fd8",
      "metadata": {},
      "source": [
        "# II. Loading and processing DOEs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c5b53133",
      "metadata": {},
      "source": [
        "## II.1. El Karoui's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "254bf816",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"r\") as f:\n",
        "    DOEs = json.load(f)\n",
        "#\n",
        "print( f'''Loaded {len(DOEs)} experiments...''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4024b46e",
      "metadata": {},
      "outputs": [],
      "source": [
        "methods = [ \"convex_optim\", \"subordination\", \"CGSV\"]\n",
        "method  = methods[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f7c49be",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_DOE_with_convex( DOE, norm=\"l2\"):\n",
        "    c = 1\n",
        "    T = np.arange(0,10, 0.2)\n",
        "    nu = np.array( [complex(0.1*a,b) for a in range(0  , 10) for b in [0.01,0.1]] )\n",
        "\n",
        "    # RMT data\n",
        "    diag = np.array( DOE[\"observed_spec\"] )\n",
        "    population_spectrum = np.array( DOE[\"population_spec\"] )\n",
        "    population_cdf      = np.array( DOE[\"population_cdf\"] )\n",
        "\n",
        "    ## El Karoui\n",
        "    tic = time.time()\n",
        "    Z = freeDeconvolution.elkaroui.build_dictionary( nu, c, diag)\n",
        "    nu_check = -(1-c)/Z + c*freeDeconvolution.elkaroui.stieltjes(Z, diag)\n",
        "    nu_errors = np.abs(nu - nu_check)\n",
        "    bad_indices = np.where(nu_errors > 1e-5)\n",
        "\n",
        "    # Clean-up if necessary\n",
        "    if len(bad_indices):\n",
        "        Z  = np.delete( Z , bad_indices )\n",
        "        nu = np.delete( nu, bad_indices )\n",
        "    dictionary = (Z, nu)\n",
        "\n",
        "    # Perform optimization\n",
        "    weights_convex, objective_value = freeDeconvolution.elkaroui.perform_cvx_optimization( dictionary, T, c, norm, verbose=False)\n",
        "    weights_convex = abs(weights_convex)\n",
        "    toc    = time.time()\n",
        "    timing = toc-tic\n",
        "    print( f'''Timing for convex optimization by el Karoui {str(timing)}''' )\n",
        "\n",
        "    ## Done\n",
        "    error   = wasserstein_distance( T, population_spectrum,  weights_convex, np.ones(len(population_spectrum))/len(population_spectrum))\n",
        "    new_DOE = DOE.copy()\n",
        "    new_DOE[\"results_by_method\"][\"convex_optim\"] = {\n",
        "        \"error\": error,\n",
        "        \"timing\": timing,\n",
        "        \"weights\": list(weights_convex),\n",
        "        \"support\": list(T)\n",
        "    }\n",
        "\n",
        "    return new_DOE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfd60d22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop over experiments\n",
        "print( \"Loop over DOEs using multiprocessing... \")\n",
        "num_processes = 12 # Use all the available CPU cores of computer\n",
        "with mp.Pool(processes=num_processes) as pool:\n",
        "    results = pool.map( compute_DOE_with_convex , DOEs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513c49dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"w\") as f:\n",
        "    json.dump( results, f, indent=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b67c6b32",
      "metadata": {},
      "source": [
        "## II.2. Tarrago's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb1d1ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"r\") as f:\n",
        "    DOEs = json.load(f)\n",
        "#\n",
        "print( f'''Loaded {len(DOEs)} experiments...''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3661bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "## II.2. Processing with the subordination method\n",
        "methods = [ \"convex_optim\", \"subordination\"]\n",
        "method  = methods[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662d1c9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_DOE_with_subordination( DOE):\n",
        "    # RMT data\n",
        "    diag = np.array( DOE[\"observed_spec\"] )\n",
        "    population_spectrum = np.array( DOE[\"population_spec\"] )\n",
        "    population_cdf      = np.array( DOE[\"population_cdf\"] )\n",
        "    \n",
        "    ## Tarrago\n",
        "    tic  = time.time()\n",
        "    y, R = freeDeconvolution.subordination.freedeconvolutionresult(diag)\n",
        "    weights_subordination = abs(R)/np.sum(R)\n",
        "    toc    = time.time()\n",
        "    timing = toc-tic\n",
        "    print( f'''Timing for convex optimization by Tarrago {str(timing)}''' )\n",
        "\n",
        "    ## Done\n",
        "    error   = wasserstein_distance( y, population_spectrum,  weights_subordination, np.ones(len(population_spectrum))/len(population_spectrum))\n",
        "    new_DOE = DOE.copy()\n",
        "    new_DOE[\"results_by_method\"][\"subordination\"] = {\n",
        "        \"error\"  : error,\n",
        "        \"timing\" : timing,\n",
        "        \"weights\": list(weights_subordination),\n",
        "        \"support\": list(y)\n",
        "    }\n",
        "\n",
        "    return new_DOE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d398d30d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop over experiments\n",
        "print( \"Loop over DOEs using multiprocessing... \")\n",
        "num_processes = 12 # Use all the available CPU cores of computer\n",
        "with mp.Pool(processes=num_processes) as pool:\n",
        "    results = pool.map( compute_DOE_with_subordination , DOEs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd86e9dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"w\") as f:\n",
        "    json.dump( results, f, indent=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c10253cc",
      "metadata": {},
      "source": [
        "## II.3. Our method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4497a727",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"r\") as f:\n",
        "    DOEs = json.load(f)\n",
        "#\n",
        "print( f'''Loaded {len(DOEs)} experiments...''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e573e4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "## II.3. Processing with our method\n",
        "methods = [ \"convex_optim\", \"subordination\", \"our method\"]\n",
        "method  = methods[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa7cb33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_DOE_with_our_method( DOE, debug=False):\n",
        "    c = 1\n",
        "    N = DOE['N']\n",
        "    p = int(c*N)\n",
        "        \n",
        "    # RMT data\n",
        "    diag = np.array( DOE[\"observed_spec\"] )\n",
        "    population_spectrum = np.array( DOE[\"population_spec\"] )\n",
        "    population_cdf      = np.array( DOE[\"population_cdf\"] )\n",
        "    \n",
        "    tic  = time.time()\n",
        "\n",
        "    ## Init\n",
        "    mu_observed = freeDeconvolution.core.DiscreteMeasure( diag, None)\n",
        "    mu_signal   = freeDeconvolution.core.DiscreteMeasure( population_spectrum, None)\n",
        "\n",
        "    mu_observed.compute_second_kind()\n",
        "\n",
        "    zeroes_first_kind   = mu_observed.zeroes_first_kind\n",
        "    zeroes_second_kind  = mu_observed.zeroes_second_kind\n",
        "\n",
        "    ## Find bounding box\n",
        "    from freeDeconvolution import boxes\n",
        "    degree = len(diag)\n",
        "\n",
        "    if debug:\n",
        "        print(\"Eigenvalues\")\n",
        "        print(\"min: \", np.min(diag))\n",
        "        print(\"max: \", np.max(diag))\n",
        "\n",
        "    mesh_size = 10000\n",
        "    # radius = np.max(diag)/2 + 1\n",
        "    # center = np.max(diag)/2\n",
        "    # interval = np.linspace(0, 2*np.pi, mesh_size)\n",
        "    # contour = center + radius*( np.cos(interval) + np.sin(interval)*1.0j)\n",
        "    # plt.scatter( np.real(diag), np.imag(diag), c='r')\n",
        "    # plt.plot( np.real(contour), np.imag(contour) )\n",
        "    # plt.show()\n",
        "\n",
        "    def index_integrand(z):\n",
        "        values = mu_observed.Markov_Krein_prime(z)/mu_observed.Markov_Krein(z)\n",
        "        return values\n",
        "\n",
        "    # values = index_integrand(contour)\n",
        "    # dz = 1.0j*(contour-center)*2*np.pi/(mesh_size) \n",
        "    # index  = np.sum(dz*values)/(2*np.pi*1.0j)\n",
        "    # print( \"Index: \", index)\n",
        "    # print( \"Root count: \", index+2*degree)\n",
        "\n",
        "    # print( \"Box segments enumeration: \")\n",
        "    # print( boxes.box_segments_enum )\n",
        "\n",
        "    def compute_index( box, mesh_size, plot=True, color='b'):\n",
        "        interval =  np.linspace( 0,1, mesh_size)\n",
        "        integral = 0\n",
        "        for segment in boxes.box_segments_enum:\n",
        "                vector = box[ segment[1] ] - box[ segment[0] ]\n",
        "                origin = box[ segment[0] ]\n",
        "                s = origin + interval*vector\n",
        "                #\n",
        "                values = index_integrand(s)\n",
        "                dz = ( s[-1]-s[0] )/mesh_size\n",
        "                integral = integral + np.sum( values*dz )\n",
        "        return integral/(2*np.pi*1.0j)\n",
        "    # TODO: Make it more versatile. Here tuning by hand of radius.\n",
        "    if debug:\n",
        "        print(\"Finding bounding box...\")\n",
        "\n",
        "    radius = 4\n",
        "    mesh_size = int(1e4)\n",
        "    bounding_box = {\n",
        "        'top_left'    : np.min(diag) - 0.3 + radius*1.0j,\n",
        "        'bottom_right': np.max(diag) + 0.3 - radius*1.0j,\n",
        "    }\n",
        "    bounding_box   = boxes.extend_box(bounding_box)\n",
        "    index = compute_index( bounding_box, mesh_size)\n",
        "    index = np.real(index+2*degree)\n",
        "    root_count = int( np.round( index ) )\n",
        "    error = index-root_count\n",
        "    if debug:\n",
        "        print( \"Index     : \", index)\n",
        "        print( \"Root count: \", \"2x\", 0.5*root_count)\n",
        "        print( \"p         : \", p)\n",
        "        print( \"\")\n",
        "\n",
        "    # If false, the bounding box missed roots\n",
        "    assert( p-1 == int(0.5*root_count))\n",
        "    \n",
        "    ## Find contour\n",
        "    box = bounding_box.copy()\n",
        "    box['bottom_left'] = box['top_left'] # For initialization, bottom_left needs to be the previous top_left\n",
        "    radius = box['height']/2\n",
        "    stop_at_first_nonempty = True        # Stop at first found box with roots\n",
        "\n",
        "    # Loop for multiple passes and more\n",
        "    boxes_with_roots = []\n",
        "    root_counter = 0\n",
        "    total_roots  = p-1 # Total number of roots in upper half plane\n",
        "    i = 0\n",
        "    while( root_counter < total_roots ):\n",
        "        i = i+1\n",
        "        radius = radius/2\n",
        "        box = {\n",
        "                'top_left'    : box['bottom_left'],\n",
        "                'bottom_right': np.real( box['bottom_right'] ) + radius*1.0j,\n",
        "        }\n",
        "        box   = boxes.extend_box(box)\n",
        "        index = compute_index( box, mesh_size, plot=False)\n",
        "        index = np.real(index)\n",
        "        root_count = int( np.round( index ) )\n",
        "        root_counter = root_counter + root_count\n",
        "        error = index-root_count\n",
        "        if debug:\n",
        "            print(f\"Pass {i}:\")\n",
        "            print( \"Index: \", index)\n",
        "            print( \"Root count / Total: \", root_count, '/', root_counter)\n",
        "            print( \"Found:\", root_counter, \" / \", total_roots )\n",
        "            print( \"\")\n",
        "        #\n",
        "        if root_count>0:\n",
        "                box['root_count'] = root_count\n",
        "                boxes_with_roots.append( box )\n",
        "                if stop_at_first_nonempty:\n",
        "                        break\n",
        "    #\n",
        "\n",
        "    ## Setup arrays\n",
        "    contour_type = \"rectangle\"\n",
        "    mesh_size    = int(1e5)\n",
        "    mid_point    = 0.5*np.min(diag) + 0.5*np.max(diag)\n",
        "\n",
        "    if contour_type==\"rectangle\":\n",
        "        path = boxes.box_to_path( bounding_box, mesh_size )\n",
        "        z_array = np.array( path )\n",
        "    \n",
        "    m_array = mu_observed.M_empirical( z_array )\n",
        "    s_array = (1+m_array)/(m_array*z_array)\n",
        "\n",
        "    # Various arrays\n",
        "    s_signal_array = s_array\n",
        "    s_noise_array  = 1/(c*m_array + 1)\n",
        "    s_deconv_array = s_signal_array/s_noise_array\n",
        "    m_deconv_array = 1/( s_deconv_array*z_array - 1)\n",
        "    #m_deconv_theoretical_array = mu_signal.M_empirical( z_array )\n",
        "    g_deconv_array = (m_deconv_array+1)/z_array\n",
        "    #g_deconv_theoretical = (m_deconv_theoretical_array+1)/z_array\n",
        "\n",
        "    ## Compute moments\n",
        "    dz_array  = z_array-np.roll(z_array, shift=1)\n",
        "    def cauchy_integral_g_deconv( f ):\n",
        "        value = g_deconv_array*f*dz_array\n",
        "        #value = g_deconv_theoretical*f*dz_array\n",
        "        return value.sum()/(2*np.pi*1.0j)\n",
        "    moments_count = 8\n",
        "    mom_array = np.zeros( 2*moments_count + 2)\n",
        "    for mom_index in range( len(mom_array) ):\n",
        "        value = cauchy_integral_g_deconv( (z_array-mid_point)**mom_index ) # Centering stabilizes\n",
        "        mom_array[ mom_index ] = np.real(value)\n",
        "    # end for\n",
        "\n",
        "    ## Inverse moment problem\n",
        "    jacobi_a, jacobi_b = freeDeconvolution.oprl.jacobi_from_moments( mom_array )\n",
        "    support, weights   = freeDeconvolution.quadrature_from_jacobi( jacobi_a, jacobi_b)\n",
        "    support = support + mid_point\n",
        "\n",
        "    toc    = time.time()\n",
        "    timing = toc-tic\n",
        "    print( f'''Timing for our method {str(timing)}''' )\n",
        "\n",
        "    ## Done\n",
        "    error   = 10+wasserstein_distance( support, population_spectrum, weights, np.ones(len(population_spectrum))/len(population_spectrum))\n",
        "    new_DOE = DOE.copy()\n",
        "    new_DOE[\"results_by_method\"][\"our method\"] = {\n",
        "        \"error\"  : error,\n",
        "        \"timing\" : timing,\n",
        "        \"weights\": list(weights),\n",
        "        \"support\": list(support)\n",
        "    }\n",
        "\n",
        "    with open( f'''./dump/DOE_{DOE['id']}.json''', \"w\") as f:\n",
        "        json.dump( new_DOE, f, indent=4)\n",
        "\n",
        "    print( \"Error  : \", error)\n",
        "    print( \"Weights: \", weights)\n",
        "    print( \"Support: \", support)\n",
        "    print( \"\" )\n",
        "    return new_DOE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff0aafe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "\n",
        "# Tag DOEs for identification if bugs\n",
        "for i in range( len(DOEs) ):\n",
        "    DOE       = DOEs[i]\n",
        "    DOE['id'] = 31000+i\n",
        "\n",
        "# Lazy mode\n",
        "lazy = True\n",
        "if lazy:\n",
        "    print( \"Working in lazy mode...\")\n",
        "    files = os.listdir('./dump')\n",
        "    str_identifiers = [ f.strip(string.ascii_letters)[1:-1] for f in files]\n",
        "    identifiers     = sorted( [ int(str_id)-31000 for str_id in str_identifiers] )\n",
        "    print( \"Found files: \", identifiers )\n",
        "    all_indices      = set( range(len(DOEs)) )\n",
        "    selected_indices = all_indices.difference( identifiers )\n",
        "    selected_indices = list(selected_indices)[:]\n",
        "    print( f'''Number of selected indices: {len(selected_indices)}/{len(DOEs)}''')\n",
        "    print( \"Selected indices:\", selected_indices)\n",
        "    selected_DOEs = [ DOEs[i] for i in selected_indices ]\n",
        "    print( \"\")\n",
        "else:\n",
        "    selected_DOEs = DOEs\n",
        "\n",
        "# Loop over experiments\n",
        "print( \"Loop over DOEs using multiprocessing... \")\n",
        "num_processes = 6 # Use all the available CPU cores of computer\n",
        "with mp.Pool(processes=num_processes) as pool:\n",
        "    results = pool.map( compute_DOE_with_our_method, selected_DOEs)\n",
        "# for DOE in selected_DOEs:\n",
        "#     compute_DOE_with_our_method( DOE )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1704ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"w\") as f:\n",
        "    json.dump( results, f, indent=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75795e13",
      "metadata": {},
      "source": [
        "## II.4. Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c6cc8e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "\n",
        "files = os.listdir('./dump')\n",
        "DOEs_fused = []\n",
        "for filename in files:\n",
        "    f = open( f'''./dump/{filename}''', 'r')\n",
        "    DOE = json.load( f )\n",
        "    DOEs_fused.append( DOE )\n",
        "# end for\n",
        "\n",
        "with open(\"./DOEs_fused.json\", \"w\") as f:\n",
        "    json.dump( DOEs_fused, f, indent=4)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "acbf1736",
      "metadata": {},
      "source": [
        "# III. Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7a3095",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"r\") as f:\n",
        "    DOEs = json.load(f)\n",
        "#\n",
        "print( f'''Loaded {len(DOEs)} experiments...''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0271d9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "methods = [ \"convex_optim\", \"subordination\", \"our method\"]\n",
        "\n",
        "aggregated_results = freeDeconvolution.plots.aggregate_benchmarks( DOEs, methods)\n",
        "freeDeconvolution.plots.make_plots( aggregated_results, methods )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4eaf711c",
      "metadata": {},
      "source": [
        "# IV. Analysis\n",
        "\n",
        "Here we dump data to csv file for further analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afa52d58",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"./DOEs_with_results.json\", \"r\") as f:\n",
        "    DOEs = json.load(f)\n",
        "#\n",
        "print( f'''Loaded {len(DOEs)} experiments...''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41bb829",
      "metadata": {},
      "outputs": [],
      "source": [
        "extracts = []\n",
        "for DOE in DOEs:\n",
        "    result   = DOE['results_by_method']['our method']\n",
        "    error    = result['error']\n",
        "    timing   = result['timing']\n",
        "    extract = [ DOE['Scenario'], DOE['N'], error, timing, result[\"weights\"], result[\"support\"] ]\n",
        "    extracts.append( extract )\n",
        "# end for\n",
        "\n",
        "import csv\n",
        "\n",
        "col_names = [\"Scenario\", \"N\", \"error\", \"timing\", \"weights\", \"support\"]\n",
        "\n",
        "with open(\"./extracts.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow( col_names )\n",
        "    writer.writerows(extracts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab49aec",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6RybRximYwwI"
      ],
      "name": "Shared_ElKaroui3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
